{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019bae9d",
   "metadata": {},
   "source": [
    "## SVM model code\n",
    "\n",
    "Jia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b7f51",
   "metadata": {},
   "source": [
    "### Import libraries and display dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16373b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries and packages\n",
    "import quadprog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#load the dataset\n",
    "df = pd.read_csv('processed_urls.csv')\n",
    "\n",
    "#display dataset information\n",
    "print(\"Dataset Column Information:\")\n",
    "print(\"=\" * 50)\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col} ({df[col].dtype})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fc9ce",
   "metadata": {},
   "source": [
    "### Split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate training and testing data\n",
    "\n",
    "#use 5000 samples for training\n",
    "subset_size = 5000\n",
    "np.random.seed(42)\n",
    "subset_indices = np.random.choice(X_train.shape[0], size=subset_size, replace=False)\n",
    "\n",
    "X_train_subset = X_train[subset_indices]\n",
    "Y_train_subset = Y_train[subset_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf2056",
   "metadata": {},
   "source": [
    "### Create Q Matrix and set up quadprog parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Q matrix\n",
    "n_samples = X_train_subset.shape[0]\n",
    "Q = np.zeros((n_samples, n_samples))\n",
    "\n",
    "print(f\"Creating Q matrix of shape ({n_samples}, {n_samples})...\")\n",
    "for i in range(n_samples):\n",
    "    for j in range(n_samples):\n",
    "        Q[i, j] = Y_train_subset[i] * Y_train_subset[j] * np.dot(X_train_subset[i], X_train_subset[j])\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"  Completed row {i + 1}/{n_samples}\")\n",
    "\n",
    "#set up rest of quadprog parameters\n",
    "P = Q + np.eye(n_samples) * 1e-5\n",
    "q = -np.ones(n_samples)\n",
    "G = -np.eye(n_samples)\n",
    "h = np.zeros(n_samples)\n",
    "A = Y_train_subset.reshape((1, n_samples))\n",
    "b = np.zeros(1)\n",
    "\n",
    "print(f\"Q matrix shape: {Q.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee1e82",
   "metadata": {},
   "source": [
    "### Solve SVM Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to solve QP\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -np.vstack([A, G]).T\n",
    "        qp_b = -np.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:\n",
    "        qp_C = -G.T\n",
    "        qp_b = -h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "#solve SVM optimization\n",
    "print(\"Solving SVM optimization problem...\")\n",
    "solution = quadprog_solve_qp(P, q, G, h, A, b)\n",
    "\n",
    "print(f\"\\nSolution shape: {solution.shape}\")\n",
    "print(f\"Number of support vectors: {np.sum(solution > 1e-5)}\")\n",
    "print(f\"Support vector indices: {np.where(solution > 1e-5)[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db6c1e",
   "metadata": {},
   "source": [
    "### Compute bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac02aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract support vectors and compute bias (b) term\n",
    "support_vector_indices = np.where(solution > 1e-5)[0]\n",
    "support_vectors = X_train_subset[support_vector_indices]\n",
    "support_vector_labels = Y_train_subset[support_vector_indices]\n",
    "alphas = solution[support_vector_indices]\n",
    "\n",
    "print(f\"Number of support vectors: {len(support_vector_indices)}\")\n",
    "\n",
    "# Compute bias term (b) using support vectors\n",
    "# For a support vector: y_i * (w^T * x_i + b) = 1\n",
    "# We use margin support vectors (0 < alpha < C) for better numerical stability\n",
    "margin_sv_indices = support_vector_indices[np.logical_and(alphas > 1e-5, alphas < 0.99)]\n",
    "\n",
    "if len(margin_sv_indices) > 0:\n",
    "\n",
    "    w = np.sum(alphas[:, np.newaxis] * support_vector_labels[:, np.newaxis] * support_vectors, axis=0)\n",
    "    \n",
    "    #compute b from margin support vectors\n",
    "    b_values = []\n",
    "    for idx in margin_sv_indices:\n",
    "        sv_idx = np.where(support_vector_indices == idx)[0][0]\n",
    "        b_val = support_vector_labels[sv_idx] - np.dot(w, support_vectors[sv_idx])\n",
    "        b_values.append(b_val)\n",
    "    \n",
    "    b_term = np.mean(b_values) if b_values else 0\n",
    "else:\n",
    "    w = np.sum(alphas[:, np.newaxis] * support_vector_labels[:, np.newaxis] * support_vectors, axis=0)\n",
    "    b_term = 0\n",
    "\n",
    "print(f\"Weight vector shape: {w.shape}\")\n",
    "print(f\"Bias term (b): {b_term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84722daa",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def predict_svm(X, w, b):\n",
    "    predictions = np.dot(X, w) + b\n",
    "    return np.sign(predictions)\n",
    "\n",
    "#make predictions on training set\n",
    "y_pred_train = predict_svm(X_train_subset, w, b_term)\n",
    "train_accuracy = np.mean(y_pred_train == Y_train_subset)\n",
    "\n",
    "#make predictions on test set\n",
    "y_pred_test = predict_svm(X_test, w, b_term)\n",
    "test_accuracy = np.mean(y_pred_test == Y_test)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SVM MODEL EVALUATION\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Accuracy:     {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4f3fd",
   "metadata": {},
   "source": [
    "### Evaluate Model (TO DO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
