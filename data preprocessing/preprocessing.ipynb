{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2283a7d0",
   "metadata": {},
   "source": [
    "## Data Preprocessing for URL dataset pulled from the Mendeley website. \n",
    "\n",
    "### This data will be used in a final course project in CS 549 Fall 2025, San Diego State University.\n",
    "\n",
    "Author: Jia Gapuz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d26e6c",
   "metadata": {},
   "source": [
    "1. Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575bb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 450,176 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url        type\n",
       "0     https://www.google.com  legitimate\n",
       "1    https://www.youtube.com  legitimate\n",
       "2   https://www.facebook.com  legitimate\n",
       "3      https://www.baidu.com  legitimate\n",
       "4  https://www.wikipedia.org  legitimate"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "csv_path = Path(\"URL dataset.csv\")\n",
    "\n",
    "# Read with fallback encoding\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding=\"latin-1\")\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46715f45",
   "metadata": {},
   "source": [
    "2. Drop exact duplicates in the dataset, print the ratio of legitimate to malicious URLS in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e771f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate rows (0.00% of original).\n",
      "\n",
      "Counts and ratios by type:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>legitimate</th>\n",
       "      <td>345738</td>\n",
       "      <td>0.768006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phishing</th>\n",
       "      <td>104438</td>\n",
       "      <td>0.231994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count     ratio\n",
       "type                        \n",
       "legitimate  345738  0.768006\n",
       "phishing    104438  0.231994"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log number of rows before removing duplicates\n",
    "original_rows = len(df)\n",
    "\n",
    "#drop exact duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#log current number of rows and print removed count\n",
    "new_rows = len(df)\n",
    "removed = original_rows - new_rows\n",
    "print(f\"Removed {removed} duplicate rows ({removed/original_rows:.2%} of original).\")\n",
    "\n",
    "# Count each type and compute ratio\n",
    "counts = df['type'].value_counts(dropna=False)\n",
    "ratio = (counts / counts.sum()).rename('ratio')\n",
    "summary = pd.concat([counts.rename('count'), ratio], axis=1)\n",
    "\n",
    "print(\"\\nCounts and ratios by type:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b5bc8",
   "metadata": {},
   "source": [
    "Since the current dataset's ratio is unaaceptable (we defined acceptable as at least 60-40), we will pull from another dataset to reach a 50-50 if possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d68947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve a 50-50 ratio, you need to add 345738 more malicious entries.\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many more malicious entries are needed for 50-50\n",
    "legit = df['type'].value_counts().get('legitimate', 0)\n",
    "malicious = df['type'].value_counts().get('malicious', 0)\n",
    "entries_needed = max(0, legit - malicious)\n",
    "print(f\"To achieve a 50-50 ratio, you need to add {entries_needed} more malicious entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95400add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             count     ratio\n",
      "type                        \n",
      "legitimate  345738  0.684721\n",
      "phishing    159195  0.315279\n"
     ]
    }
   ],
   "source": [
    "phish_df = pd.read_csv(\"Phishing URLs.csv\")\n",
    "\n",
    "# Ensure we append exactly 'entries_needed' new URLs by excluding existing ones first\n",
    "existing_urls = set(df['url'].astype(str)) if 'url' in df.columns else set()\n",
    "candidates = phish_df[\"url\"].astype(str).dropna().drop_duplicates()\n",
    "unique_new = candidates[~candidates.isin(existing_urls)]\n",
    "\n",
    "to_use = unique_new.head(int(entries_needed))\n",
    "rows_to_append = pd.DataFrame({\n",
    "    'url': to_use.values,\n",
    "    'type': ['phishing'] * len(to_use)\n",
    "})\n",
    "\n",
    "#append entries\n",
    "df = pd.concat([df, rows_to_append], ignore_index=True)\n",
    "\n",
    "#turn all 'malicious' labels into 'phishing'\n",
    "df['type'] = df['type'].replace({'malicious': 'phishing'})\n",
    "\n",
    "#print summary\n",
    "counts = df['type'].value_counts(dropna=False)\n",
    "ratio = (counts / counts.sum()).rename('ratio')\n",
    "summary = pd.concat([counts.rename('count'), ratio], axis=1)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603b163",
   "metadata": {},
   "source": [
    "3. Ensure all entries are in lowercase, relabel legitimate entries to a 0 and phishing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9587050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url  type\n",
       "0     https://www.google.com     0\n",
       "1    https://www.youtube.com     0\n",
       "2   https://www.facebook.com     0\n",
       "3      https://www.baidu.com     0\n",
       "4  https://www.wikipedia.org     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in obj_cols:\n",
    "    mask = df[col].notna()\n",
    "    df.loc[mask, col] = df.loc[mask, col].str.strip().str.lower()\n",
    "\n",
    "#relabel the type column to 1 or 0\n",
    "if 'type' in df.columns:\n",
    "    df['type'] = df['type'].map({'legitimate': 0, 'phishing': 1})\n",
    "\n",
    "#display a few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028c9d9",
   "metadata": {},
   "source": [
    "4. Use a parsing library (ie urllib.parse) to extract and append the following information:\n",
    "\n",
    "Scheme\n",
    "Subdomain\n",
    "Registrable domain\n",
    "Suffix\n",
    "Path\n",
    "Query\n",
    "Fragment\n",
    "Port\n",
    "Username\n",
    "Password\n",
    "Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3ce022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>registrable_domain</th>\n",
       "      <th>suffix</th>\n",
       "      <th>path</th>\n",
       "      <th>query</th>\n",
       "      <th>fragment</th>\n",
       "      <th>port</th>\n",
       "      <th>username</th>\n",
       "      <th>password</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>google.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>baidu.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.baidu.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>org</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.wikipedia.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scheme subdomain registrable_domain suffix path query fragment port  \\\n",
       "0  https       www         google.com    com                            \n",
       "1  https       www        youtube.com    com                            \n",
       "2  https       www       facebook.com    com                            \n",
       "3  https       www          baidu.com    com                            \n",
       "4  https       www      wikipedia.org    org                            \n",
       "\n",
       "  username password               host  \n",
       "0                       www.google.com  \n",
       "1                      www.youtube.com  \n",
       "2                     www.facebook.com  \n",
       "3                        www.baidu.com  \n",
       "4                    www.wikipedia.org  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# Optional robust domain parsing\n",
    "try:\n",
    "    import tldextract\n",
    "    has_tldextract = True\n",
    "except ImportError:\n",
    "    has_tldextract = False\n",
    "\n",
    "\n",
    "def parse_url(u: str):\n",
    "    parsed = urlparse(u)\n",
    "    host = parsed.hostname or ''\n",
    "    # Handle port safely - urlparse.port may raise ValueError for invalid ports\n",
    "    try:\n",
    "        port = parsed.port if parsed.port is not None else ''\n",
    "    except ValueError:\n",
    "        # If port cannot be parsed, extract it manually or set to empty\n",
    "        port = ''\n",
    "    username = parsed.username or ''\n",
    "    password = parsed.password or ''\n",
    "    scheme = parsed.scheme or ''\n",
    "    path = parsed.path or ''\n",
    "    query = parsed.query or ''\n",
    "    fragment = parsed.fragment or ''\n",
    "\n",
    "    # Domain parts\n",
    "    if has_tldextract and host:\n",
    "        ext = tldextract.extract(host)\n",
    "        subdomain = ext.subdomain or ''\n",
    "        registrable_domain = (ext.domain + '.' + ext.suffix) if ext.domain and ext.suffix else (ext.domain or '')\n",
    "        suffix = ext.suffix or ''\n",
    "    else:\n",
    "        parts = host.split('.') if host else []\n",
    "        suffix = parts[-1] if len(parts) >= 1 else ''\n",
    "        domain = parts[-2] if len(parts) >= 2 else ''\n",
    "        subdomain = '.'.join(parts[:-2]) if len(parts) >= 3 else ''\n",
    "        registrable_domain = (domain + ('.' + suffix if suffix else '')) if domain else ''\n",
    "\n",
    "    return {\n",
    "        'scheme': scheme,\n",
    "        'subdomain': subdomain,\n",
    "        'registrable_domain': registrable_domain,\n",
    "        'suffix': suffix,\n",
    "        'path': path,\n",
    "        'query': query,\n",
    "        'fragment': fragment,\n",
    "        'port': port,\n",
    "        'username': username,\n",
    "        'password': password,\n",
    "        'host': host,\n",
    "    }\n",
    "\n",
    "components = df['url'].astype(str).fillna('').apply(parse_url)\n",
    "comp_df = pd.DataFrame(list(components))\n",
    "\n",
    "# Append columns to df (align by index)\n",
    "df = pd.concat([df, comp_df], axis=1)\n",
    "\n",
    "# Preview new columns\n",
    "df[['scheme','subdomain','registrable_domain','suffix','path','query','fragment','port','username','password','host']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d52217",
   "metadata": {},
   "source": [
    "5. Add two new columns to flag http and https entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a410d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>scheme</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>registrable_domain</th>\n",
       "      <th>suffix</th>\n",
       "      <th>path</th>\n",
       "      <th>query</th>\n",
       "      <th>fragment</th>\n",
       "      <th>port</th>\n",
       "      <th>username</th>\n",
       "      <th>password</th>\n",
       "      <th>host</th>\n",
       "      <th>is_http</th>\n",
       "      <th>is_https</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>google.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.google.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>baidu.com</td>\n",
       "      <td>com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>org</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url  type scheme subdomain registrable_domain suffix  \\\n",
       "0     https://www.google.com     0  https       www         google.com    com   \n",
       "1    https://www.youtube.com     0  https       www        youtube.com    com   \n",
       "2   https://www.facebook.com     0  https       www       facebook.com    com   \n",
       "3      https://www.baidu.com     0  https       www          baidu.com    com   \n",
       "4  https://www.wikipedia.org     0  https       www      wikipedia.org    org   \n",
       "\n",
       "  path query fragment port username password               host  is_http  \\\n",
       "0                                                www.google.com        0   \n",
       "1                                               www.youtube.com        0   \n",
       "2                                              www.facebook.com        0   \n",
       "3                                                 www.baidu.com        0   \n",
       "4                                             www.wikipedia.org        0   \n",
       "\n",
       "   is_https  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_series = df['url'].astype(str).fillna('')\n",
    "df['is_http'] = np.where(url_series.str.startswith('http://'), 1, 0)\n",
    "df['is_https'] = np.where(url_series.str.startswith('https://'), 1, 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37973c",
   "metadata": {},
   "source": [
    "6. Count and append the following lengths:  \n",
    "    a. Total length  \n",
    "    b. Host length  \n",
    "    c. Path length  \n",
    "    d. Query length  \n",
    "    e. Fragment length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4237a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added length columns: len_total, len_host, len_path, len_query, len_fragment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_total</th>\n",
       "      <th>len_host</th>\n",
       "      <th>len_path</th>\n",
       "      <th>len_query</th>\n",
       "      <th>len_fragment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   len_total  len_host  len_path  len_query  len_fragment\n",
       "0         22        14         0          0             0\n",
       "1         23        15         0          0             0\n",
       "2         24        16         0          0             0\n",
       "3         21        13         0          0             0\n",
       "4         25        17         0          0             0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and append URL length features\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Ensure 'url' exists\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot compute length features.\")\n",
    "\n",
    "url_s = df['url'].astype(str).fillna('')\n",
    "\n",
    "# Prefer already-parsed columns if present; otherwise parse on the fly\n",
    "if 'host' in df.columns:\n",
    "    host_s = df['host'].astype(str).fillna('')\n",
    "else:\n",
    "    host_s = url_s.apply(lambda u: urlparse(u).hostname or '')\n",
    "\n",
    "if 'path' in df.columns:\n",
    "    path_s = df['path'].astype(str).fillna('')\n",
    "else:\n",
    "    path_s = url_s.apply(lambda u: urlparse(u).path or '')\n",
    "\n",
    "if 'query' in df.columns:\n",
    "    query_s = df['query'].astype(str).fillna('')\n",
    "else:\n",
    "    query_s = url_s.apply(lambda u: urlparse(u).query or '')\n",
    "\n",
    "if 'fragment' in df.columns:\n",
    "    fragment_s = df['fragment'].astype(str).fillna('')\n",
    "else:\n",
    "    fragment_s = url_s.apply(lambda u: urlparse(u).fragment or '')\n",
    "\n",
    "# Add length columns\n",
    "df['len_total'] = url_s.str.len()\n",
    "df['len_host'] = host_s.str.len()\n",
    "df['len_path'] = path_s.str.len()\n",
    "df['len_query'] = query_s.str.len()\n",
    "df['len_fragment'] = fragment_s.str.len()\n",
    "\n",
    "print(\"Added length columns: len_total, len_host, len_path, len_query, len_fragment\")\n",
    "\n",
    "df[['len_total','len_host','len_path','len_query','len_fragment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266663d",
   "metadata": {},
   "source": [
    "7. Count and append the counts the following characters:  \n",
    "    a. Dots  \n",
    "    b. Slashes  \n",
    "    c. Other special characters (ie -, _, %, @, ?, =, &)  \n",
    "    d. Digits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f0ed618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_dots</th>\n",
       "      <th>count_slashes</th>\n",
       "      <th>count_digits</th>\n",
       "      <th>count_special</th>\n",
       "      <th>count_hyphen</th>\n",
       "      <th>count_underscore</th>\n",
       "      <th>count_percent</th>\n",
       "      <th>count_at</th>\n",
       "      <th>count_question</th>\n",
       "      <th>count_equal</th>\n",
       "      <th>count_ampersand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_dots  count_slashes  count_digits  count_special  count_hyphen  \\\n",
       "0           2              2             0              0             0   \n",
       "1           2              2             0              0             0   \n",
       "2           2              2             0              0             0   \n",
       "3           2              2             0              0             0   \n",
       "4           2              2             0              0             0   \n",
       "\n",
       "   count_underscore  count_percent  count_at  count_question  count_equal  \\\n",
       "0                 0              0         0               0            0   \n",
       "1                 0              0         0               0            0   \n",
       "2                 0              0         0               0            0   \n",
       "3                 0              0         0               0            0   \n",
       "4                 0              0         0               0            0   \n",
       "\n",
       "   count_ampersand  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count and append character occurrence features\n",
    "import pandas as pd\n",
    "\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot compute character counts.\")\n",
    "\n",
    "url_s = df['url'].astype(str).fillna('')\n",
    "\n",
    "# Core counts\n",
    "df['count_dots'] = url_s.str.count(r'\\.')\n",
    "df['count_slashes'] = url_s.str.count('/')\n",
    "df['count_digits'] = url_s.str.count(r'\\d')\n",
    "\n",
    "# Individual special characters\n",
    "df['count_hyphen'] = url_s.str.count('-')\n",
    "df['count_underscore'] = url_s.str.count('_')\n",
    "df['count_percent'] = url_s.str.count('%')\n",
    "df['count_at'] = url_s.str.count('@')\n",
    "df['count_question'] = url_s.str.count(r'\\?')\n",
    "df['count_equal'] = url_s.str.count('=')\n",
    "df['count_ampersand'] = url_s.str.count('&')\n",
    "\n",
    "# Aggregate special count (from the listed characters)\n",
    "special_cols = [\n",
    "    'count_hyphen','count_underscore','count_percent',\n",
    "    'count_at','count_question','count_equal','count_ampersand'\n",
    "]\n",
    "df['count_special'] = df[special_cols].sum(axis=1)\n",
    "\n",
    "# Preview of new columns\n",
    "df[['count_dots','count_slashes','count_digits','count_special'] + special_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52bc09",
   "metadata": {},
   "source": [
    "8. Calculate and append the Shannon entropy of the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3f68e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added entropy column: entropy_url\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.663533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.762267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.855389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.880180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.813661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entropy_url\n",
       "0     3.663533\n",
       "1     3.762267\n",
       "2     3.855389\n",
       "3     3.880180\n",
       "4     3.813661"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and append Shannon entropy of URL entries\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot compute entropy.\")\n",
    "\n",
    "url_s = df['url'].astype(str).fillna('')\n",
    "\n",
    "def shannon_entropy(s: str) -> float:\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    counts = Counter(s)\n",
    "    n = len(s)\n",
    "    return -sum((c/n) * math.log2(c/n) for c in counts.values() if c)\n",
    "\n",
    "# Entropy of full URL string\n",
    "df['entropy_url'] = url_s.apply(shannon_entropy)\n",
    "\n",
    "print(\"Added entropy column: entropy_url\")\n",
    "\n",
    "df[['entropy_url']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb398560",
   "metadata": {},
   "source": [
    "9. Flag the following keywords  \n",
    "a. Login  \n",
    "b. Verify  \n",
    "c. Update  \n",
    "d. Secure  \n",
    "e. Account  \n",
    "f. Bank  \n",
    "g. Paypal  \n",
    "h. Free  \n",
    "i. Prize  \n",
    "j. Gift  \n",
    "k. Confirm  \n",
    "l. Win  \n",
    "m. Signin  \n",
    "n. Support   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ba5ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jia Gapuz\\AppData\\Local\\Temp\\ipykernel_16992\\4254183981.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df['keyword_flag'] = text.str.contains(pattern, na=False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows flagged: 34,226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>keyword_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url  keyword_flag\n",
       "0     https://www.google.com             0\n",
       "1    https://www.youtube.com             0\n",
       "2   https://www.facebook.com             0\n",
       "3      https://www.baidu.com             0\n",
       "4  https://www.wikipedia.org             0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag URLs containing any of the specified keywords\n",
    "import re\n",
    "\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot flag keywords.\")\n",
    "\n",
    "keywords = [\n",
    "    'login','verify','update','secure','account','bank','paypal',\n",
    "    'free','prize','gift','confirm','win','signin','support'\n",
    "]\n",
    "pattern = re.compile(r'(' + '|'.join(map(re.escape, keywords)) + r')', flags=re.IGNORECASE)\n",
    "\n",
    "text = df['url'].astype(str).fillna('')\n",
    "df['keyword_flag'] = text.str.contains(pattern, na=False).astype(int)\n",
    "\n",
    "# Ensure the new column appears at the end explicitly\n",
    "cols = list(df.columns)\n",
    "cols.append(cols.pop(cols.index('keyword_flag')))\n",
    "df = df[cols]\n",
    "\n",
    "print(f\"Total rows flagged: {df['keyword_flag'].sum():,}\")\n",
    "\n",
    "df[['url','keyword_flag']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696f7c",
   "metadata": {},
   "source": [
    "10. Flag link shorteners (ie. bit.ly, t.co, tinyurl.com, goo.gl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d976f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shorteners flagged: 1,474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>registrable_domain</th>\n",
       "      <th>is_shortener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url registrable_domain  is_shortener\n",
       "0     https://www.google.com         google.com             0\n",
       "1    https://www.youtube.com        youtube.com             0\n",
       "2   https://www.facebook.com       facebook.com             0\n",
       "3      https://www.baidu.com          baidu.com             0\n",
       "4  https://www.wikipedia.org      wikipedia.org             0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag common link shorteners in URLs\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Known URL shortener registrable domains (expand as needed)\n",
    "shorteners = {\n",
    "    'bit.ly', 't.co', 'tinyurl.com', 'goo.gl'\n",
    "}\n",
    "\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot flag link shorteners.\")\n",
    "\n",
    "# Choose the best available field for matching\n",
    "if 'registrable_domain' in df.columns:\n",
    "    base = df['registrable_domain'].astype(str).str.lower()\n",
    "elif 'host' in df.columns:\n",
    "    base = df['host'].astype(str).str.lower()\n",
    "else:\n",
    "    base = df['url'].astype(str).fillna('').apply(lambda u: (urlparse(u).hostname or '').lower())\n",
    "\n",
    "# Create flag column\n",
    "is_short = base.isin(shorteners).astype(int)\n",
    "df['is_shortened'] = is_short\n",
    "\n",
    "# Move the new column to the end explicitly\n",
    "cols = list(df.columns)\n",
    "cols.append(cols.pop(cols.index('is_shortened')))\n",
    "df = df[cols]\n",
    "\n",
    "print(f\"Total shorteners flagged: {int(is_short.sum()):,}\")\n",
    "\n",
    "# Preview\n",
    "preview_cols = ['url']\n",
    "if 'registrable_domain' in df.columns:\n",
    "    preview_cols.append('registrable_domain')\n",
    "elif 'host' in df.columns:\n",
    "    preview_cols.append('host')\n",
    "preview_cols.append('is_shortener')\n",
    "df[preview_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3b6bf",
   "metadata": {},
   "source": [
    "11. Flag all domains that are purely IP numbers (ie http://101.10.1.101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bfb93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IP hosts flagged: 4,411\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>host</th>\n",
       "      <th>is_ip_host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.google.com</td>\n",
       "      <td>www.google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>www.youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com</td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.baidu.com</td>\n",
       "      <td>www.baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikipedia.org</td>\n",
       "      <td>www.wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         url               host  is_ip_host\n",
       "0     https://www.google.com     www.google.com           0\n",
       "1    https://www.youtube.com    www.youtube.com           0\n",
       "2   https://www.facebook.com   www.facebook.com           0\n",
       "3      https://www.baidu.com      www.baidu.com           0\n",
       "4  https://www.wikipedia.org  www.wikipedia.org           0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag hosts that are pure IP addresses (IPv4 or IPv6)\n",
    "from urllib.parse import urlparse\n",
    "import ipaddress\n",
    "\n",
    "if 'url' not in df.columns:\n",
    "    raise KeyError(\"Column 'url' not found; cannot flag IP hosts.\")\n",
    "\n",
    "# Prefer previously parsed host if available\n",
    "if 'host' in df.columns:\n",
    "    host_s = df['host'].astype(str).fillna('')\n",
    "else:\n",
    "    host_s = df['url'].astype(str).fillna('').apply(lambda u: (urlparse(u).hostname or ''))\n",
    "\n",
    "\n",
    "def is_ip_host(h: str) -> int:\n",
    "    try:\n",
    "        ipaddress.ip_address(h)\n",
    "        return 1\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# Create flag\n",
    "df['is_ip_host'] = host_s.apply(is_ip_host).astype(int)\n",
    "\n",
    "# Move the column to the end explicitly\n",
    "cols = list(df.columns)\n",
    "cols.append(cols.pop(cols.index('is_ip_host')))\n",
    "df = df[cols]\n",
    "\n",
    "print(f\"Total IP hosts flagged: {int(df['is_ip_host'].sum()):,}\")\n",
    "\n",
    "# Preview\n",
    "preview_cols = ['url']\n",
    "if 'host' in df.columns:\n",
    "    preview_cols.append('host')\n",
    "preview_cols.append('is_ip_host')\n",
    "df[preview_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5c38317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 504,933 rows x 36 columns to C:\\Users\\Jia Gapuz\\Desktop\\cs549-final-project\\data preprocessing\\processed_urls.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to CSV\n",
    "from pathlib import Path\n",
    "\n",
    "#print out df preview\n",
    "df.head()\n",
    "\n",
    "output_path = Path(\"processed_urls.csv\")  # change name/path if desired\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved {len(df):,} rows x {df.shape[1]} columns to {output_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
